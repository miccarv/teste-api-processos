version: "3"

networks:
  my-network:

services:
  crawler:
    container_name: crawler
    build:
      context: ./web-crawler
      dockerfile: Dockerfile
    environment:
      - NODE_ENV=production
    restart: always
    ports:
      - "8081:8081"
    networks:
      - my-network
    depends_on:
      elasticsearch:
        condition: service_healthy

  frontend:
    container_name: frontend
    build:
      context: ./frontend
      dockerfile: Dockerfile
    environment:
      - NODE_ENV=production
    restart: always
    ports:
      - "3000:3000"
    networks:
      - my-network
    depends_on:
      elasticsearch:
        condition: service_healthy

  backend:
    container_name: backend
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      - SPRING_PROFILES_ACTIVE=production
    restart: always
    ports:
      - "8080:8080"
    networks:
      - my-network
    depends_on:
      elasticsearch:
        condition: service_healthy

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.6.2
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - esdata:/usr/share/elasticsearch/data
    networks:
      - my-network
    healthcheck:
      test: ["CMD-SHELL", "curl --silent --fail http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

volumes:
  esdata:
    driver: local

